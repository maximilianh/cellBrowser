#!/usr/bin/env python3

# scanpy exists only in python3, so this script works only in python3

# runs a single cell matrix through scanpy and output 
# everything as tab-sep files

# large parts were written by Lucas Seninge

import logging, sys, optparse, re, timeit, datetime
from time import gmtime, strftime
from collections import defaultdict, namedtuple, Counter
from os.path import join, basename, dirname, isfile, isdir, abspath, splitext
from os import makedirs

# directory to static data files, e.g. gencode tables
dataDir = join(dirname(__file__), "static", "human")
mitoFname = join(dataDir, "gencode22Plus.mitoGenes.txt")

import warnings
warnings.filterwarnings("ignore")

import sys
sys.path.append( join(dirname(__file__), "cbLib") )
import cellbrowser

# ==== functions =====
# for iphython debug command line
def excepthook(type, value, traceback):
    from IPython import embed
    embed()

def parseArgs():
    " setup logging, parse command line arguments and options. -h shows auto-generated help page "
    parser = optparse.OptionParser("""usage: %prog [options] -e matrixFile -o outDir - run scanpy and output .tsv files

    If exceptions occur, will automatically start the debugger.
    """)

    parser.add_option("-e", "--exprMatrix", dest="exprMatrix", action="store",
            help="gene-cell expression matrix file, possible formats: .h5ad, .csv, .xlsx, .h5, .loom, .mtx, .txt, .tab, .data")
    #parser.add_option("-m", "--metaData", dest="metaData", action="store",
            #help="meta data table file, .gz is OK")

    parser.add_option("-o", "--outDir", dest="outDir", action="store",
            help="output directory")

    parser.add_option("-s", "--samplesOnRows", dest="samplesOnRows", action="store_true",
            help="when reading the expression matrix from a text file, assume that samples are on lines (default behavior is one-gene-per-line, one-sample-per-column)")

    parser.add_option("-n", "--name", dest="name", action="store", default="cbScanpy-Data",
            help="name of dataset in cell browser, default %default")

    parser.add_option("", "--test",
        dest="test",
        action="store_true", help="run doctests")
    parser.add_option("-d", "--debug", dest="debug", action="store_true", help="open an iPython shell when an exception occurs. also output debug messages")

    (options, args) = parser.parse_args()

    if options.test:
        import doctest
        doctest.testmod()
        sys.exit(0)

    if options.exprMatrix is None and options.outDir is None:
        parser.print_help()
        exit(1)

    if options.debug:
        logging.basicConfig(level=logging.DEBUG)
        #import sys
        #import IPython # just making sure that ipython is installed. install with 'pip install ipython'
        #sys.excepthook = excepthook

    else:
        logging.basicConfig(level=logging.INFO)
    return args, options

def errAbort(msg):
        logging.error(msg)
        sys.exit(1)

def cbScanpy(matrixFname, figDir, logFname):
    " run expr matrix through scanpy, output "
    import scanpy.api as sc
    from scanpy.logging import info
    import pandas as pd
    import numpy as np

    sc.settings.set_figure_params(dpi=200)
    sc.settings.file_format_figs = 'png'
    sc.settings.plot_suffix=''
    sc.settings.autosave=True
    sc.settings.autoshow=False
    sc.settings.figdir=figDir
    sc.settings.logfile=logFname
    #sc.settings.logDir=join(outDir, "cbScanpy.log")

    info("cbScanpy $Id$")
    info("Input file: %s" % matrixFname)
    #print("Output directory: %s" % outDir)
    info("Start time: %s" % datetime.datetime.now())
    sc.logging.print_versions()

    start = timeit.default_timer()
    if matrixFname.endswith(".mtx"):
        logging.info("Loading expression matrix: mtx format")
        adata = sc.read(matrixFname).T

        mtxDir = dirname(matrixFname)
        adata.var_names = pd.read_csv(join(mtxDir, 'genes.tsv'), header=None, sep='\t')[1]
        adata.obs_names = pd.read_csv(join(mtxDir, 'barcodes.tsv'), header=None)[0]

    else:
        adata = sc.read(matrixFname, cache=True , first_column_names=True)
        if not options.samplesOnRows:
            info("Transposing the expression matrix")
            adata = adata.T

    info("Data has %d samples/observations" % len(adata.obs))
    info("Data has %d genes/variables" % len(adata.var))

    minGenes = 200
    minCells = 3
    info("Basic filtering: keep only cells with min %d genes and genes seen in at least %d cells" % (minGenes, minCells))
    sc.pp.filter_cells(adata, min_genes=minGenes)
    sc.pp.filter_genes(adata, min_cells=minCells)

    #### PARAMETERS FOR GATING CELLS (must be changed) #####
    thrsh_mito=0.05
    up_thrsh_genes=2500
    low_thrsh_genes=10
    info("Remove cells with more than",thrsh_mito,"percent of mitochondrial genes")
    info("Remove cells with less than", low_thrsh_genes, "and more than", up_thrsh_genes, "genes")

    info("Computing percentage of mitochondrial genes")
    mito_genes = [name for name in adata.var_names if name.startswith('MT.') or name.startswith('MT-')]
    if len(mito_genes)==0:
        info("Reading mitochondrial genes from %s" % mitoFname)
        gencodeMitos = open(mitoFname).read().splitlines()
        gencodeMitos = set([x.split(".")[0] for x in gencodeMitos]) # strip version number
        mito_genes = [name for name in adata.var_names if name.split('.')[0] in gencodeMitos]

    if(len(mito_genes)==0): # no single mitochondrial gene in the expression matrix ?
        info("WARNING - No single mitochondrial gene was found in the expression matrix.")
        info("Dying cells cannot be removed - please check your expression matrix")
        doMito = False
    else:
        doMito = True

        adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1) / np.sum(adata.X, axis=1)
        adata.obs['n_counts'] = np.sum(adata.X, axis=1)

        sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'], jitter=0.4, multi_panel=True)

        fig1=sc.pl.scatter(adata, x='n_counts', y='percent_mito', save="_percent_mito")
        fig2=sc.pl.scatter(adata, x='n_counts', y='n_genes', save="_gene_count")

        adata = adata[adata.obs['percent_mito'] < thrsh_mito, :]

    #Filtering out cells according to filter parameters
    info('Filtering cells')
    adata = adata[adata.obs['n_genes'] < up_thrsh_genes, :]
    adata = adata[adata.obs['n_genes'] > low_thrsh_genes, :]

    info("After filtering: Data has %d samples/observations and %d genes/variables" % (len(adata.obs), len(adata.var)))

    countsPerCell = 10000
    info('Expression normalization, counts per cell = %d' % countsPerCell)
    sc.pp.normalize_per_cell(adata, counts_per_cell_after=countsPerCell)

    minMean = 0.0125
    maxMean = 3
    minDisp = 0.5
    info('Finding highly variable genes: min_mean=%f, max_mean=%f, min_disp=%f' % (minMean, maxMean, minDisp))
    filter_result = sc.pp.filter_genes_dispersion(adata.X, min_mean=minMean, max_mean=maxMean, min_disp=minDisp)
    sc.pl.filter_genes_dispersion(filter_result)
    adata = adata[:, filter_result.gene_subset]

    sc.pp.log1p(adata)

    #Regress out variables nUMI, percent_mito
    info('Number of variable genes identified:', sum(filter_result.gene_subset))

    if doMito:
        info('Regressing out percent_mito and number of UMIs')
        sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])
    else:
        info('Regressing out only number of UMIs')
        sc.pp.regress_out(adata, ['n_counts'])

    #Scaling after regression 
    maxValue = 10
    info('Scaling data, max_value=%d' % maxValue)
    sc.pp.scale(adata, max_value=maxValue)

    pcCount = 100
    info('Performing PCA, number of PCs: %d' % pcCount)
    sc.tl.pca(adata, n_comps=pcCount)
    #Multiply by -1 to compare with Seurat
    #adata.obsm['X_pca'] *= -1
    #Plot of pca variance ratio to see if formula matches visual determination of pc_nb to use
    sc.pl.pca_variance_ratio(adata, log=True )

    #Computing number of PCs to be used in clustering
    pc_cutoff= (np.sqrt((adata.n_vars/adata.n_obs))+1)**2
    pc_nb=0
    for i in adata.uns['pca']['variance']:
        if i>pc_cutoff:
            pc_nb+=1
    info(pc_nb,' PCs will be used for tSNE and clustering')

    info('Performing tSNE')
    sc.tl.tsne(adata, n_pcs=int(pc_nb), random_state=2, n_jobs=8)

    neighbors = 10
    info('Performing Louvain Clustering, using %d neighbors' % neighbors)
    sc.pp.neighbors(adata, n_pcs=int(pc_nb), n_neighbors=neighbors)
    sc.tl.louvain(adata, resolution=2.5)
    sc.pl.tsne(adata, color='louvain')

    #Clustering. Default Resolution: 1
    res = 1.0
    info('Performing Louvain Clustering, resolution = %f' % res)
    sc.pp.neighbors(adata, n_pcs=int(pc_nb))
    sc.tl.louvain(adata, resolution=res)
    sc.pl.tsne(adata, color='louvain')

    info("Performing UMAP")
    sc.tl.umap(adata)

    #info("Performing PHATE")
    #sc.tl.phate(adata)

    info("Performing PAGA+ForceAtlas2")
    sc.tl.paga(adata, groups='louvain')
    sc.pl.paga(adata, threshold=0.01, show=False)
    sc.tl.draw_graph(adata, init_pos='paga')
    adata.obsm["X_pagaFa2"] = adata.obsm["X_draw_graph_fa"]

    info("Performing ForceAtlas2")
    sc.tl.draw_graph(adata)

    #info("Performing PAGA+UMAP")
    #sc.tl.umap(adata, init_pos='paga') # waiting for key_added_ext PR

    #Finding Top Markers, according to z-score
    info('Finding top markers for each cluster')
    sc.tl.rank_genes_groups(adata, 'louvain')
    sc.pl.rank_genes_groups(adata, n_genes=20)

    #Stop Timer
    stop= timeit.default_timer()
    info("Running time:",stop-start)

    return adata

def writeConf(name, outDir):
    for c in name:
        assert(c.isalnum()) # only digits and letters are allowed in dataset names

    coords = [
        ("tsne", "Scanpy t-SNE"),
        ("umap", "Scanpy UMAP"),
        ("fa2", "Scanpy ForceAtlas2"),
        ("phate", "Scanpy PHATE"),
        ("pagaFa2", "Scanpy PAGA+ForceAtlas2"),
    ]

    coordsList = []
    for prefix, label in coords:
        fname = prefix+"_coords.tsv"
        if isfile(join(outDir, fname)):
            coordsList.append({"file":fname, "shortLabel" : label})

    conf = """
name='%(name)s'
shortLabel='%(name)s'
exprMatrix='exprMatrix.tsv'
#tags = ["10x", 'smartseq2']
meta='cell_to_cluster.tsv'
geneIdType='symbols'
clusterField='Louvain Cluster'
labelField='Louvain Cluster'
enumFields=['Louvain Cluster']
markers = [{"file": "markers.tsv", "shortLabel":"Cluster Markers"}]
coords=%(coordsList)s
radius=10
alpha=0.8
""" % locals()
    
    fname = join(outDir, 'cellbrowser.conf')
    if isfile(fname):
        logging.info("Not overwriting %s, file already exists." % fname)
        return

    ofh = open(fname, "w")
    ofh.write(conf)
    ofh.close()

# ----------- main --------------
def main():
    global options
    args, options = parseArgs()

    #try:
    matrixFname = options.exprMatrix
    outDir = options.outDir

    if not isdir(outDir):
        logging.info("Creating output directory %s" % outDir)
        makedirs(outDir)

    figDir = join(outDir, "figs")

    adFname = join(outDir, "anndata.h5ad")

    if not isfile(adFname):
        logFname = join(outDir, "cbScanpy.log")
        adata = cbScanpy(matrixFname, figDir, logFname)
        logging.info("Writing anndata object to %s" % adFname)
        adata.write(adFname)
    else:
        import scanpy.api as sc
        logging.info("Looks like the scanpy analysis was run before")
        logging.info("Reading old cached anndata from %s" % adFname)
        adata = sc.read(adFname)

    cellbrowser.scanpyToTsv(adata, outDir)
    # on an exception, automatically bring up the debugger - avoids having to reload the data file
    #except:
        #extype, value, tb = sys.exc_info()
        #import traceback, pdb
        #traceback.print_tb(tb)
        #pdb.post_mortem(tb)

    writeConf(options.name, options.outDir)

main()
